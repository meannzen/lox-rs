use std::{iter::Peekable, str::Chars};
#[derive(Debug, PartialEq, Clone)]
pub struct Token {
    pub kind: TokenKind,
    pub literal: String,
    pub line: usize,
    pub column: usize,
}

#[derive(Debug, PartialEq, Clone, Copy)]
pub enum TokenKind {
    LeftParen,
    RightParen,
    LeftBrace,
    RightBrace,
    Star,
    Dot,
    Comma,
    Plus,
    Minus,
    Semi,
    Slash,
    Equal,
    EqualEqual,
    Bang,
    BangEqual,
    Less,
    LessEqual,
    Greater,
    GreaterEqual,
    String,
    Number(f64),
    Identifier,
    And,
    Class,
    Else,
    False,
    For,
    Fun,
    If,
    Nil,
    Or,
    Print,
    Return,
    Super,
    This,
    True,
    Var,
    While,
    Illegal(IlligalType),
}

#[derive(Debug, PartialEq, Clone, Copy)]
pub enum IlligalType {
    Unexpected,
    UnterminatedString,
}

impl std::fmt::Display for Token {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match &self.kind {
            TokenKind::LeftParen => write!(f, "LEFT_PAREN ( null"),
            TokenKind::RightParen => write!(f, "RIGHT_PAREN ) null"),
            TokenKind::LeftBrace => write!(f, "LEFT_BRACE {{ null"),
            TokenKind::RightBrace => write!(f, "RIGHT_BRACE }} null"),
            TokenKind::Star => write!(f, "STAR * null"),
            TokenKind::Dot => write!(f, "DOT . null"),
            TokenKind::Comma => write!(f, "COMMA , null"),
            TokenKind::Plus => write!(f, "PLUS + null"),
            TokenKind::Minus => write!(f, "MINUS - null"),
            TokenKind::Semi => write!(f, "SEMICOLON ; null"),
            TokenKind::Slash => write!(f, "SLASH / null"),
            TokenKind::Equal => write!(f, "EQUAL = null"),
            TokenKind::EqualEqual => write!(f, "EQUAL_EQUAL == null"),
            TokenKind::Bang => write!(f, "BANG ! null"),
            TokenKind::BangEqual => write!(f, "BANG_EQUAL != null"),
            TokenKind::Less => write!(f, "LESS < null"),
            TokenKind::LessEqual => write!(f, "LESS_EQUAL <= null"),
            TokenKind::Greater => write!(f, "GREATER > null"),
            TokenKind::GreaterEqual => write!(f, "GREATER_EQUAL >= null"),
            TokenKind::String => write!(f, "STRING \"{}\" {}", self.literal, self.literal),
            TokenKind::Number(num) => {
                if num.fract() == 0.0 {
                    write!(f, "NUMBER {} {:.1}", self.literal, num)
                } else {
                    write!(f, "NUMBER {} {num}", self.literal)
                }
            }
            TokenKind::Identifier => write!(f, "IDENTIFIER {} null", self.literal),
            TokenKind::And => write!(f, "AND {} null", self.literal),
            TokenKind::Class => write!(f, "CLASS {} null", self.literal),
            TokenKind::Else => write!(f, "ELSE {} null", self.literal),
            TokenKind::For => write!(f, "FOR {} null", self.literal),
            TokenKind::Fun => write!(f, "FUN {} null", self.literal),
            TokenKind::If => write!(f, "IF {} null", self.literal),
            TokenKind::False => write!(f, "FALSE {} null", self.literal),
            TokenKind::Nil => write!(f, "NIL {} null", self.literal),
            TokenKind::Or => write!(f, "OR {} null", self.literal),
            TokenKind::Print => write!(f, "PRINT {} null", self.literal),
            TokenKind::Return => write!(f, "RETURN {} null", self.literal),
            TokenKind::This => write!(f, "THIS {} null", self.literal),
            TokenKind::True => write!(f, "TRUE {} null", self.literal),
            TokenKind::Var => write!(f, "VAR {} null", self.literal),
            TokenKind::While => write!(f, "WHILE {} null", self.literal),
            TokenKind::Super => write!(f, "SUPER {} null", self.literal),
            TokenKind::Illegal(ty) => {
                let word = match ty {
                    IlligalType::UnterminatedString => "Unterminated string .".to_string(),
                    IlligalType::Unexpected => format!("Unexpected character: {}", self.literal),
                };

                write!(f, "[line {}] Error: {}", self.line, word)
            }
        }
    }
}

pub struct Lexer<'c> {
    input: Peekable<Chars<'c>>,
    line: usize,
    column: usize,
}

impl<'c> Lexer<'c> {
    pub fn new(input: &'c str) -> Self {
        Lexer {
            input: input.chars().peekable(),
            line: 1,
            column: 1,
        }
    }

    fn advance(&mut self) -> Option<char> {
        let ch = self.input.next()?;
        if ch == '\n' {
            self.line += 1;
            self.column = 1;
        } else {
            self.column += 1;
        }
        Some(ch)
    }

    fn next_token(&mut self) -> Option<Token> {
        self.skip_whitespace();

        let start_line = self.line;
        let start_column = self.column;

        let ch = self.advance()?;

        let mut literal: String = ch.to_string();

        let kind = match ch {
            '(' => TokenKind::LeftParen,
            ')' => TokenKind::RightParen,
            '{' => TokenKind::LeftBrace,
            '}' => TokenKind::RightBrace,
            '*' => TokenKind::Star,
            '.' => TokenKind::Dot,
            ',' => TokenKind::Comma,
            '+' => TokenKind::Plus,
            '-' => TokenKind::Minus,
            ';' => TokenKind::Semi,
            '/' => {
                if self.input.next_if_eq(&'/').is_some() {
                    self.next_line();
                    return self.next_token();
                } else {
                    TokenKind::Slash
                }
            }
            '=' => {
                if let Some(next_ch) = self.input.next_if_eq(&'=') {
                    literal.push(next_ch);
                    TokenKind::EqualEqual
                } else {
                    TokenKind::Equal
                }
            }
            '!' => {
                if let Some(next_ch) = self.input.next_if_eq(&'=') {
                    literal.push(next_ch);
                    TokenKind::BangEqual
                } else {
                    TokenKind::Bang
                }
            }
            '<' => {
                if let Some(next_ch) = self.input.next_if_eq(&'=') {
                    literal.push(next_ch);
                    TokenKind::LessEqual
                } else {
                    TokenKind::Less
                }
            }
            '>' => {
                if let Some(next_ch) = self.input.next_if_eq(&'=') {
                    literal.push(next_ch);
                    TokenKind::GreaterEqual
                } else {
                    TokenKind::Greater
                }
            }
            '"' => {
                literal = String::new();
                let mut found_closing_quote = false;
                while let Some(c) = self.advance() {
                    if c == '"' {
                        found_closing_quote = true;
                        break;
                    }
                    literal.push(c);
                }

                if found_closing_quote {
                    TokenKind::String
                } else {
                    TokenKind::Illegal(IlligalType::UnterminatedString)
                }
            }
            '0'..='9' => {
                let mut number = String::from(ch);
                while let Some(&c) = self.input.peek() {
                    if c.is_ascii_digit() {
                        number.push(c);
                        self.advance();
                    } else {
                        break;
                    }
                }
                let mut temp_input = self.input.clone();
                if temp_input.next_if_eq(&'.').is_some() {
                    if let Some(c) = temp_input.next() {
                        if c.is_ascii_digit() {
                            self.advance();
                        }
                    }
                    let mut next_number = String::new();
                    while let Some(&c) = self.input.peek() {
                        if c.is_ascii_digit() {
                            next_number.push(c);
                            self.advance();
                        } else {
                            break;
                        }
                    }

                    if !next_number.is_empty() {
                        number.push('.');
                        number.push_str(&next_number);
                    }
                }
                let num: f64 = number.parse().unwrap();
                literal = number;
                TokenKind::Number(num)
            }
            'a'..='z' | 'A'..='Z' | '_' => {
                while let Some(&next) = self.input.peek() {
                    if !next.is_whitespace() || next.is_ascii_digit() || next == '_' {
                        if next.is_ascii_punctuation() && next != '_' {
                            break;
                        }
                        literal.push(next);
                        self.advance();
                    } else {
                        break;
                    }
                }
                match literal.as_str() {
                    "and" => TokenKind::And,
                    "class" => TokenKind::Class,
                    "else" => TokenKind::Else,
                    "false" => TokenKind::False,
                    "for" => TokenKind::For,
                    "fun" => TokenKind::Fun,
                    "if" => TokenKind::If,
                    "nil" => TokenKind::Nil,
                    "or" => TokenKind::Or,
                    "print" => TokenKind::Print,
                    "return" => TokenKind::Return,
                    "super" => TokenKind::Super,
                    "this" => TokenKind::This,
                    "true" => TokenKind::True,
                    "var" => TokenKind::Var,
                    "while" => TokenKind::While,
                    _ => TokenKind::Identifier,
                }
            }
            _ => TokenKind::Illegal(IlligalType::Unexpected),
        };

        Some(Token {
            kind,
            literal,
            line: start_line,
            column: start_column,
        })
    }

    fn skip_whitespace(&mut self) {
        while let Some(&c) = self.input.peek() {
            if c.is_ascii_whitespace() {
                self.advance();
            } else {
                break;
            }
        }
    }

    fn next_line(&mut self) {
        while let Some(&c) = self.input.peek() {
            if c != '\n' {
                self.advance();
            } else {
                break;
            }
        }
    }
}

impl Iterator for Lexer<'_> {
    type Item = Token;
    fn next(&mut self) -> Option<Self::Item> {
        self.next_token()
    }
}
#[cfg(test)]
mod tests {
    use crate::{Lexer, Token, TokenKind};

    #[test]
    fn empty() {
        let mut lexer = Lexer::new("");
        let token = lexer.next();
        assert_eq!(token, None);
    }

    #[test]
    fn scanning_parentheses() {
        let input = " ( ( ) ) ";
        let lexer = Lexer::new(input);

        let expected_tokens = vec![
            Token {
                kind: TokenKind::LeftParen,
                literal: "(".to_string(),
                line: 1,
                column: 2,
            },
            Token {
                kind: TokenKind::LeftParen,
                literal: "(".to_string(),
                line: 1,
                column: 4,
            },
            Token {
                kind: TokenKind::RightParen,
                literal: ")".to_string(),
                line: 1,
                column: 6,
            },
            Token {
                kind: TokenKind::RightParen,
                literal: ")".to_string(),
                line: 1,
                column: 8,
            },
        ];

        let actual_tokens: Vec<Token> = lexer.collect();

        assert_eq!(actual_tokens, expected_tokens);
    }

    #[test]
    fn scanning_brace() {
        let input = " {{ }} ";
        let lexer = Lexer::new(input);

        let expected_tokens = vec![
            Token {
                kind: TokenKind::LeftBrace,
                literal: "{".to_string(),
                line: 1,
                column: 2,
            },
            Token {
                kind: TokenKind::LeftBrace,
                literal: "{".to_string(),
                line: 1,
                column: 3,
            },
            Token {
                kind: TokenKind::RightBrace,
                literal: "}".to_string(),
                line: 1,
                column: 5,
            },
            Token {
                kind: TokenKind::RightBrace,
                literal: "}".to_string(),
                line: 1,
                column: 6,
            },
        ];

        let actual_tokens: Vec<Token> = lexer.collect();

        assert_eq!(actual_tokens, expected_tokens);
    }

    #[test]
    fn scanning_symbols() {
        let input = "{*.,+*-/;})";
        let lexer = Lexer::new(input);

        let expected_tokens = vec![
            Token {
                kind: TokenKind::LeftBrace,
                literal: "{".to_string(),
                line: 1,
                column: 1,
            },
            Token {
                kind: TokenKind::Star,
                literal: "*".to_string(),
                line: 1,
                column: 2,
            },
            Token {
                kind: TokenKind::Dot,
                literal: ".".to_string(),
                line: 1,
                column: 3,
            },
            Token {
                kind: TokenKind::Comma,
                literal: ",".to_string(),
                line: 1,
                column: 4,
            },
            Token {
                kind: TokenKind::Plus,
                literal: "+".to_string(),
                line: 1,
                column: 5,
            },
            Token {
                kind: TokenKind::Star,
                literal: "*".to_string(),
                line: 1,
                column: 6,
            },
            Token {
                kind: TokenKind::Minus,
                literal: "-".to_string(),
                line: 1,
                column: 7,
            },
            Token {
                kind: TokenKind::Slash,
                literal: "/".to_string(),
                line: 1,
                column: 8,
            },
            Token {
                kind: TokenKind::Semi,
                literal: ";".to_string(),
                line: 1,
                column: 9,
            },
            Token {
                kind: TokenKind::RightBrace,
                literal: "}".to_string(),
                line: 1,
                column: 10,
            },
            Token {
                kind: TokenKind::RightParen,
                literal: ")".to_string(),
                line: 1,
                column: 11,
            },
        ];

        let actual_tokens: Vec<Token> = lexer.collect();

        assert_eq!(actual_tokens, expected_tokens);
    }

    #[test]
    fn scanning_with_newline() {
        let input = "{\n}";
        let lexer = Lexer::new(input);

        let expected_tokens = vec![
            Token {
                kind: TokenKind::LeftBrace,
                literal: "{".to_string(),
                line: 1,
                column: 1,
            },
            Token {
                kind: TokenKind::RightBrace,
                literal: "}".to_string(),
                line: 2,
                column: 1,
            },
        ];

        let actual_tokens: Vec<Token> = lexer.collect();

        assert_eq!(actual_tokens, expected_tokens);
    }

    #[test]
    fn scanning_equal_bang() {
        let input = "===!=!<<=>>=";
        let lexer = Lexer::new(input);

        let expected_tokens = vec![
            Token {
                kind: TokenKind::EqualEqual,
                literal: "==".to_string(),
                line: 1,
                column: 1,
            },
            Token {
                kind: TokenKind::Equal,
                literal: "=".to_string(),
                line: 1,
                column: 2,
            },
            Token {
                kind: TokenKind::BangEqual,
                literal: "!=".to_string(),
                line: 1,
                column: 3,
            },
            Token {
                kind: TokenKind::Bang,
                literal: "!".to_string(),
                line: 1,
                column: 4,
            },
            Token {
                kind: TokenKind::Less,
                literal: "<".to_string(),
                line: 1,
                column: 5,
            },
            Token {
                kind: TokenKind::LessEqual,
                literal: "<=".to_string(),
                line: 1,
                column: 6,
            },
            Token {
                kind: TokenKind::Greater,
                literal: ">".to_string(),
                line: 1,
                column: 7,
            },
            Token {
                kind: TokenKind::GreaterEqual,
                literal: ">=".to_string(),
                line: 1,
                column: 8,
            },
        ];

        let actual_tokens: Vec<Token> = lexer.collect();

        assert_eq!(actual_tokens, expected_tokens);
    }
}
